\section{Compact analysis objects}
CMS and ATLAS experiments are transitioning towards more compact datasets for analysis with event sizes in the order of the kB/event. This implies that a full analysis dataset will be close to 1PB per year, if we take CMS numbers on their compact analysis objects (nanoAOD \cite{nano}). This number is largely lower than the 50PB per year for older analysis objects (miniAOD)\footnote{ these sizes have been estimated taking as a reference LHC delivery of 80 billion events/year (data) and the production of 160 billion events/year (MC) together with expected sizes for the different data types of 7.4MB(RAW), 2.0MB(AOD), 200kB(miniAOD) and 4kB(nanoAOD)}. These compact objects open the window to evaluate new ways of doing computing and offer different options for the sites currently providing computing and storage resources. In particular storage has been identified as the main challenge for HL-LHC due to the increasing volume of disk storage used, and also the costs from the site perspective to operate and maintain complex storage systems.\\
One of the goals of the working group is to study the feasibility to exploit these new analysis data format and their reduction in size to promote less demanding storage at the sites (e.g. stateless storage) while fostering efforts towards computing resources (CPU, GPU, Machine Learning, etc.) with the possibility to access the full analysis datasets from a centralized storage through caches in order to minimize latency and increase file re-usability at site or even at federation/regional level.\\
Engagement of the physics community will be crucial to converge on these new compact objects. The common goal is to maximize the physics potential of the LHC machine and take as much data as possible, which translates into maximizing the efficiency of the storage resources.\\
