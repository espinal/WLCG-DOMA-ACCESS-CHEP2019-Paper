\section{Compact analysis objects}
CMS and ATLAS experiments are moving towards compact datasets for analysis with event sizes on the order of the kB/event. This implies that for CMS the full analysis datasets will around 1PB per year for this compact model named nanoAOD (c.f. with 50PB per year for miniAOD) taking as a basis the estimation of having 80(data)+160(MC) billion events/year and mean sizes for the different data types of 7.4MB(RAW), 2.0MB(AOD), 200kB(miniAOD) and 4kB(nanoAOD).
This new objects open the window to evaluate new ways of doing computing and different options for the sites providing computing and storage resources.\\
In particular storage has been identified as the main challenge for HL-LHC due to the increasing use of disk and the need for site operation and administration of complex storage systems. From the working group perspective one of the goals is to study the feasibility to exploit this new analysis objects and its reduction in size to promote less demanding storage at the sites (e.g. stateless storage) while fostering the efforts towards providing more efficient computing resources. The option to have a full analysis objects in a centralized storage while data access is performed through caches to minimize latency and increase file re-usability at site or regional level. At this point in time there is the need of the engagement from the physics community to converge using these objects but the goal is clearly to be able to maximise the physics potential of the machine and hence taking as much data as possible which means to maximise the use and efficiency of the global storage resources. Use of storage is a delicate concept, a full storage does not mean it is used in an efficient way.\\
